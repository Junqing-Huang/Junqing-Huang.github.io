<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Artistic Stylization Algorithm for Images and Videos | Junqing  Huang</title>
    <meta name="author" content="Junqing  Huang">
    <meta name="description" content="Develop (deep) learning-based methods for image and video artistic stylization, style transfer, and non-photorealistic image rendering, etc..">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/projects/research_image_stylization/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Artistic Stylization Algorithm for Images and Videos",
      "description": "Develop (deep) learning-based methods for image and video artistic stylization, style transfer, and non-photorealistic image rendering, etc..",
      "comments": "A long-term part-time project",
      "published": "July 20, 2021",
      "authors": [
        {
          "author": "Junqing Huang<sup>&#9833</sup>",
          "authorURL": "https://ruzhansky.org",
          "affiliations": [
            {
              "name": "<sup>&#9833</sup>Analysis, Logic and Discrete Mathematics, Department of Mathematics, Ghent University",
              "url": ""
            }
          ]
        }
        ,
        
        {
          "author": "Michael Ruzhansky<sup>&#9833,&#9834</sup>",
          "authorURL": "https://ruzhansky.org",
          "affiliations": [
            {
              "name": "<sup>&#9834</sup>School of Mathematical Sciences, Queen Mary University of London",
              "url": ""
            }
          ]
        }
        ,
        
        {
          "author": "Qianying Zhang<sup>&#9835</sup>",
          "authorURL": "",
          "affiliations": [
            {
              "name": "<sup>&#9835</sup>Shenzhen Institute of Information Technology",
              "url": ""
            }
          ]
        }
        ,
        
        {
          "author": "Haihui Wang<sup>&#9836</sup>",
          "authorURL": "https://math.buaa.edu.cn/szdw/axbck/yysxx/whh.htm",
          "affiliations": [
            {
              "name": "<sup>&#9836</sup>School of Mathematics, Beihang University",
              "url": ""
            }
          ]
        }
        
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JunqingÂ </span>Huang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Home</a>
              </li>
              
              
              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Code/Software</a>
              </li>

              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Gallery</a>
              </li>


              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <div class="l-page">
          <h1>Artistic Stylization Algorithm for Images and Videos</h1>
          
            <h2>(A long-term part-time project)</h2>
        </div>
      </d-title>
  
      <d-byline></d-byline> 
      
    

      <d-article>
        <!--<d-contents>
            <nav class="l-text figcaption">
            <h3>Contents</h3>
              <div><a href="#abstract">Abstract</a></div>
              <div><a href="#introduction">Introduction</a></div>
              <div><a href="#footnotes">Footnotes</a></div>
              <div><a href="#code-blocks">Code Blocks</a></div>
              <div><a href="#layouts">Layouts</a></div>
              <div><a href="#other-typography">Other Typography?</a></div>
              
            </nav>
        </d-contents>-->
        <div class="l-page">
          <div class="row mt-3"> 
  <div class="col-sm-12 mt-3 mt-md-0">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_1.png" class="img-fluid " width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
</div>
<div class="caption">
    Figure 1. Image illumination and reflectance mapping in the logarithmic intentsity domain. From (a)-(d) top: local illumination mapping (a=[0.3, 0.1, -0.1, -0.3]), middle: global illumination mapping (b=[0.6, 0.9, 1.1, 1.4]), bottom: global reflectance mapping (c=[0.5, 0.8, 1.2, 1.5]).
</div>

<h2 id="abstract">Abstract:</h2>

<p>We present a novel intrinsic image transfer (IIT) algorithm for image illumination manipulation, which creates a local image translation between two illumination surfaces. This model is built on an optimization-based framework composed of illumination, reflectance and content photo-realistic losses, respectively. Each loss is firstly defined on the corresponding sub-layers factorized by an intrinsic image decomposition and then reduced under the well-known spatial-varying illumination illumination-invariant reflectance prior knowledge. We illustrate that all losses, with the aid of an âexemplarâ image, can be directly defined on images without the necessity of taking an intrinsic image decomposition, thereby giving a closed-form solution to image illumination manipulation. We also demonstrate its versatility and benefits to several illumination-related tasks: illumination compensation, image enhancement and tone mapping, and high dynamic range (HDR) image compression, and show their high-quality results on natural image datasets.</p>

<h2 id="intrinsic-images-model">Intrinsic Images Model</h2>

<p>In many existing Retinex-based model <d-cite key="barrow1978recovering, rother2011recovering"></d-cite>, an image \(\mathcal{I}\) is assumed to be factorized into illumination \(\mathcal{L}\) and reflectance \(\mathcal{R}\),</p>

\[\begin{equation}\label{eq:eq1}
	\begin{aligned}
		\mathcal{I=L\odot R,}
	\end{aligned}
\end{equation}\]

<p>where \({\odot}\) is a point-wise multiplication operator, \(\mathcal{L}\) represents the light-dependent properties such as shading, shadows or specular highlights of images, and \(\mathcal{R}\) represents the material-dependent properties, known as the reflectance of a scene. \(\mathcal{L}\) and \(\mathcal{R}\) take rather different roles in controlling the image color, contrast, brightness and so on. Such an image decomposition has formed a basis for many intrinsic image decomposition methods<d-cite key="rother2011recovering, bell2014intrinsic, horn1974determining, land1977retinex"></d-cite>.</p>

<p><strong>Limitations:</strong> Eq. (\ref{eq:eq1})is a highly under-constraint problem if no further assumption is imposed on illumination \(\mathcal{L}\) or reflectance \(\mathcal{R}\). Suppose a high-quality intrinsic image decomposition is available, we depict the role of layer-remapping operators in aforementioned illumination-related tasks. As suggested in <d-cite key="rother2011recovering"></d-cite>, we consider a simple linear mapping model \({\hat{I} = a + bL + cR}\) in the logarithmic domain, where \(\), \(\) and \(\) are the logarithmic counterparts: \({\mathcal{I}}\), \(\mathcal{L}\) and \(\mathcal{R}\), respectively. It is clear in Figure 1 that \(a\) mainly controls the local brightness and contrast of illumination \(\) and \(b\) plays a similar role but acts globally, while \(c\) affects the global brightness and contrast of the reflectance \(\). It is usually to keep \(c=1\) invariant unless the reflectance layer \(\) needs to be adjusted in some situations because of the illumination-independent nature.</p>

<p>Obviously, the visual results can be greatly affected by the parameters \(a, b\) and \(c\). In practice, such layer-remapping operators may be implemented in a more complex form, for example, using a spatial-varying or adaptive mapping function for high-quality image illumination manipulation results. No matter in what form, such a strategy has limitations due to the facts:</p>

<ul>
	<li> intrinsic image decomposition is a highly under-constrained problem, and the estimation of each sub-layer highly relies on the prior knowledge</li>
  <li> it is not very easy to determine an appropriate layer-remapped operator for the sub-layers even with a high-quality image decomposition; </li>
  <li> the artifacts introduced by layer-remapping and image construction are not easy to control for out of the image decomposition. </li>
</ul>

<h2 id="observations">Observations</h2>

<p>The drawbacks can be significantly alleviated by integrating the intrinsic image decomposition, layer-remapping and image reconstruction into a generalized optimization-based framework. Such a strategy enables us to control image illumination in an implicit way â that is, to regularize each sub-layer without the necessity of taking an explicit intrinsic image decomposition. The advantages mainly arise from the well-known spatial-varying illumination and illumination-invariant reflectance prior knowledge. We briefly list them as follows:</p>

<ul>
	<li> Spatial-smoothing illumination --- that is, illumination $L$ has the spatial-smoothing property, while the majority of dramatic variations such as strong or salient edges, textures and structures are attributed to reflectance ${R}$. </li>
	<li> Illumination-invariant reflectance --- that is, reflectance $R$ tends to be invariant under varying illumination conditions. It is straightforward to claim that the local geometric structures formed by the dramatic variations in $R$ have the same illumination-invariant property. </li>
	<li> The visibility of an image is primarily determined by illumination ${L}$, the intensities of which may be, locally or globally, compensated or corrected for its discrepancy to the target one, especially under varying illumination conditions. Human vision system is not so sensitive to the absolute change of illumination as that of reflectance due to the "color-consistency" phenomenon.  </li>
</ul>

<p>The first assumption motivates us to use smoothing filters to approximate image illumination, because the abundant dramatic varying features are divided into reflectance. The second one implies that the illumination-invariant property of image reflectance can be constrained by regularizing the varying features equivalently. The last one indicates that image illumination should be approximated to a balanced one under the degradation illumination situations.</p>

<h2 id="illumination-manipulation-model">Illumination Manipulation Model</h2>

<p>Let \(S\) and \(O\) be the input and output images with \({s_i}\) and \({o_i}\) denoted as pixel intensities, respectively, the output image \(O\) can be expressed as an optimal solution of the following minimization problem,</p>

\[\begin{equation}\label{eq:eq2}
	\begin{aligned}
		\mathop{\min}_{o} E(o) = {\alpha} E^l(o) + {\beta} E^r(o) + {\gamma}E^c(o),
	\end{aligned}
\end{equation}\]

<p>where photorealistic loss \(E\) includes three terms \({E^l,E^r}\) and \({E^c}\) which are defined on illumination, reflectance and content respectively. \({\alpha, \beta, \gamma}\) control the balance of three terms.</p>

<h3>Illumination loss:</h3>

<p>Due to the varying illumination condition, it may suffer from great image illumination degradation in many practical illumination-related tasks. In this case, it is always desirable to restore the degraded illumination into a fine-balanced one. Suppose that an extra image \({c=\{c_i\}_{i=1}^N}\) has the ideal latent illumination \({c^l}\), it is appropriate to impose the output illumination \({o^l}\) to be close to the latent one \({c^l}\), leading to the illumination loss \({E^l(o)}\),</p>

\[\begin{equation}
	\label{eq:eq3}
	\begin{aligned}
		E^l(o)= {\sum_{i} {(o_i^l-{c}_{i}^{l})}^2},
	\end{aligned}
\end{equation}\]

<p>where \(o_i^l\)  and \(c_i^l\)  are the \(i\)-th pixel illumination of output and latent images, respectively; and the up-index \(l\) represents that Eq. (\ref{eq:eq3}) is defined on the illumination layers. An ideal image \(c\) is obviously not available in advance, but, as we illustrate hereafter, it is possible to be approximated with the aid of a so-called âexemplarâ image in terms of its role in guiding the image illumination.</p>

<p>Notice that the definition of Eq. (\ref{eq:eq3}) needs a complex intrinsic image decomposition. Recalling the spatial-smoothing property of illumination \(L\), it is possible to apply a filter on images and treat the smoothing results as the illumination layers. Considering a simple Gaussian-like smoothing kernel \(K\), the illumination \(o_i^l\) can be represented as,</p>

\[\begin{equation}
	\label{eq:eq4}
	\begin{aligned}
		o_i^l &amp; = \sum_{j\in N_i} K_{i,j} {o}_{j}, \quad \sum_{j\in{N_i}} K_{i,j}=1,\\
		&amp; K_{i,j}\propto{\text{exp}\left(-\frac{1}{\delta_f^2}{\left\Vert f_i-f_j \right\Vert}_2^2\right)},
	\end{aligned}
\end{equation}\]

<p>where \(N_{i}\) denotes a neighbor set of the \({i}\)-th pixel, \(K_{i,j}\) is the Gaussian kernel weight between the pixel \({i}\) and \({j}\); and \({f}\) is a feature vector with standard deviation \(\delta_{f}\). \({f}\) can be the pixelâs position, intensity, chromaticity or abstract features. We suggest that \({E^l({o})}\) can be defined as,</p>

\[\begin{equation}
	\label{eq:eq5}
	\begin{aligned}
		E^l(o)= \sum_{i}\sum_{j\in{N_i}}(K_{i,j}^o {o}_{j}-K_{i,j}^c {c}_{j})^2,
	\end{aligned}
\end{equation}\]

<p>where \(K_{i,j}^o\) and \({K}_{i,j}^c\) are corresponding filter kernels. 
In this case, Eq. (\ref{eq:eq5}) plays an identical role as Eq. (\ref{eq:eq3})  in measuring the illumination loss under the spatial-smoothing property. The benefit of introducing the filter kernel \({K}\) is to simplify the illumination loss without taking an explicit image decomposition.</p>

<h3>Reflectance loss:</h3>
<p>Recall the illumination-invariant property of reflectance layers, it is highly reasonable to expect the output reflectance \({o^r}\) to be identical to \({s^r}\), that of original image. In such a sense, we define \(E^r(o)\) as,</p>

\[\begin{equation}
	\label{eq:eq6}
	\begin{aligned}
    E^r(o)= {\sum_{i} {(o_i^r-{s}_{i}^{r})}^2},
	\end{aligned}
\end{equation}\]

<p>where \(s_i^r\) and \(o_i^r\) are the \({i}\)-th pixels values of the corresponding reflectance layers. Again, Eq. (\ref{eq:eq6}) requires an ill-posed intrinsic image decomposition. Notice that the reflectance layer \(R\) is assumed to have abundant features such as salient edges, lines and textures and have the same illumination-invariant property, which motivates us to control \(R\) by regularizing these features. Mathematically, we use a local linear model to encode these features, that is,  each point of the reflectance layer can be expressed as a weighted sum of its neighbors,</p>

\[\begin{equation}
	\label{eq:eq7}
	\begin{aligned}
		s^r_i={\sum_{j \in \Omega_i} {\omega_{i,j}^{s^r} {s^r_j}}},
	\end{aligned}
\end{equation}\]

<p>where \(\Omega_i\) is a neighbor of pixel \({i}\) and the weight \(\omega_{i,j}^{s^r}\) satisfies \(\sum_{j \in \Omega_i} \omega_{i,j}^{s^r}=1\). 
%The main idea of the Eq. (\ref{eq:eq7}) is to encode the pairwise relationship of the points \({s^r_i}\) and its neighbors \({s^r_j}\) into weights \(\omega_{i,j}^{s^r}\). 
It is plausible that if the reflectance \(s^r\) keeps invariant, the weight \(\omega_{i,j}^{s^r}\) is invariant as well. By analogy with the output \(o^r\), the photorealistic reflectance loss can be reformulated into the following constraints equivalently,</p>

\[\begin{equation}
	\label{eq:eq8}
	\begin{aligned}
		\begin{cases}
			&amp;{o_i^r}= {\sum_{j \in \Omega_i}{\omega_{i,j}^{o^r}}{o_j^r}}, \quad \sum_{j \in \Omega_i}{\omega_{i,j}^{o^r}}=1,\\
			&amp;{s_i^r}= {\sum_{j \in \Omega_i}{\omega_{i,j}^{s^r}}{s_j^r}}, \quad \sum_{j \in \Omega_i} {\omega_{i,j}^{s^r}}=1,\\
			&amp;{\omega_{i,j}^{o^r}} = {\omega_{i,j}^{s^r}}.
		\end{cases}
	\end{aligned}
\end{equation}\]

<p>where \(\omega_{i,j}^{o^r}\) and \(\omega_{i,j}^{s^r}\) represent the weights, and the up-index \({s^r}\) and \({o^r}\) denote that the local linear âencodingâ operators are acted on the reflectance layers. In the Eq. (\ref{eq:eq8}), we force \(\omega_{i,j}^{o^r}=\omega_{i,j}^{s^r}\)  to give a structural-consistency constraint for the reflectance layers.</p>

<div class="row justify-content-md-center"> 
  <div class="col col-lg-8">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_2.png" class="img-fluid " width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
</div>
<div class="caption">
    Figure 2. The 1-D signal ${I}$ is decomposed into three basic components: a spatial-varying ${L}$,  a detail texture layer and a salient edge.  We attribute the texture and edge into the reflectance ${R}$ in our intrinsic image model.
</div>

<p>Recall the spatial-varying illumination, we have \(s^l_k \approx \bar{s^l_k}\) with mean value \(\bar{s^l_k}\) in local patch \({k}\). Besides, if two patches \({i}\) and \({j}\)  are close to each other, we also have \(\bar{s^l_i} \approx \bar{s^l_j}\). As shown in Figure 2,  the two claims are valid in both flat regions (Top) and strong edges (Bottom). Substituting them into Eq. (\ref{eq:eq7}) we can further simplify the âencodingâ model into,</p>

\[\begin{equation}
	\label{eq:eq9}
	\begin{aligned}
		{s}_{i} &amp;=({s}^{r}_{i}+s^l_i) \approx ({s}^{r}_{i}+\bar{s^l_i}) = ({\sum\nolimits_{j \in \Omega_{i}}{\omega_{i,j}^{s^r}}s^r_j}+\bar{s^l_i}) \\
		&amp;= \sum\nolimits_{j \in \Omega_{i}}{\omega_{i,j}^{s^r}}(s^r_j+\bar{s^l_i}) \approx \sum\nolimits_{j \in \Omega_{i}}{\omega_{i,j}^{s^r}}(s^r_j+\bar{s^l_j}) \\
		&amp;\approx \sum\nolimits_{j \in \Omega_{i}}{\omega_{i,j}^{s^r}}(s^r_j+s^l_j)=\sum\nolimits_{j \in \Omega_{i}}{\omega_{i,j}^{s^r}}{s_j}.
	\end{aligned}
\end{equation}\]

<p>As we can see, Eq. (\ref{eq:eq9}) and (\ref{eq:eq7}) have the same form and \({\omega_{i,j}^{s^r}}\) keeps invariant when adding a constant illumination \({\bar{s^l_i}}\) back. Due to the translation-invariant property of local linear model, the reflectance layer can be directly regularized without the necessity of decoupling the reflectance from an image. Putting Eq. (\ref{eq:eq7}) and (9) into Eq. (\ref{eq:eq8}), we have reflectance loss \({E^r(o)}\),</p>

\[\begin{equation}
	\label{eq:eq10}
	\begin{aligned}
		&amp;E^r(o)={\sum_{i} {(o_i-{\sum_{j \in \Omega_{i}}{\omega_{i,j}^{o}}{o_j}})}^2}\\
		\text{s.t.}&amp;\quad {\omega_{i,j}^{o}}= {\omega_{i,j}^{s}}, \quad {s_i}= \sum_{j \in \Omega_{i}}{\omega_{i,j}^s s_j},
	\end{aligned}
\end{equation}\]

<p>where \({\omega_{i,j}^{s}}={\omega_{i,j}^{s^r}}\) and \({\omega_{i,j}^{o}}={\omega_{i,j}^{o^r}}\) for local âencodingâ weights. The relationship between Eq. (\ref{eq:eq8}) and Eq. (\ref{eq:eq10}) is clear, as the first constraint in Eq. (\ref{eq:eq8}) is chosen as the objective function and the others act as constraints. As we can see, Eq.(\ref{eq:eq10}) contributes an identical regularizing role as  Eq. (\ref{eq:eq6}). The simplification roots in the translation-invariant property of locally linear embedding (LLE)<d-cite key="roweis2000nonlinear"></d-cite>, which helps to faithfully penalty non-consistent structures despite the local illumination deviation between the input and exemplar images. Moreover, this reduction enables us to translate the reflectance layer from the source illumination surface to that of the exemplar, while keeping the reflectance layer from changing.</p>

<h3>Content loss:</h3>
<p>We additionally introduce a so-called content loss to avoid the illumination over-fitting problem, which may occur when the pre-computed examplar has a strong over-stretched illumination. The content loss, in such cases, helps to give a remedy for the output global illumination. Specifically, we define the content loss \({E^c(o)}\) as,</p>

\[\begin{equation}
	\label{eq:eq11}
	\begin{aligned}
		E^c(o)&amp;=\sum_{i} {(o_i-s_i)}^2.
	\end{aligned}
\end{equation}\]

<p>We can verify that Eq.(\ref{eq:eq11}) is essentially defined on the illumination layers.  We also have \({E^c(o)=\sum_{i} (o_i^l-o_i^r+s_i^l-s_i^r)^2=\sum_{i} (o_i^l-s_i^l)^2}\) with \({o_i^r} = {s_i^r}\) under the illumination-invariant property of the reflectance layer. It is valuable to note that \({E^c(o)}\) is not always necessary but plays an auxiliary role to prevent output illumination from being over-dependent on exemplars.</p>

<h2 id="optimization">Optimization</h2>

<p>Now, we combine three loss functions and rewrite Eq. (\ref{eq:eq12}) in a matrix form:</p>

\[\begin{equation}
	\label{eq:eq12}
	\begin{aligned}
		E(o) =&amp;\alpha {\left\Vert K^o o-K^c c \right\Vert}_2^2+\beta{\left\Vert M o \right\Vert }_2^2+\gamma{\left\Vert \boldsymbol{o-s}\right\Vert }_2^2, \\
		&amp;\text{s.t.} \quad \omega_{i,j}^{o}= {\omega_{i,j}^s}, \quad {s_i}= {\sum_{j \in \Omega_{i}}\omega_{i,j}^{s} s_j},
	\end{aligned}
\end{equation}\]

<p>where \({K^{o}(K^{c})}\) is a kernel affinity matrix, whose \({(i,j)}\)th entry is \({K_{i,j}^{o(c)}}\); and \({M=[I-W]}\) is a sparse coefficient matrix with identity \({I}\) and weight \({W}\) containing entries \({\omega_{i,j}^{o}}\). Once \({K^o}\), \({K^c}\) and \({W}\) are pre-computed, the output image can be reconstructed by solving the Eq. (\ref{eq:eq12}) directly.</p>

<p>We first compute the filter kernel \({K}\). The simplest case can be the \({2}\)-D Gaussian filter (GF), where \({f}\) relies on pixelâs position: \({p=[p_x, p_y]}\) with the \({x}\) and \({y}\) directional coordinates \({p_x}\) and \({p_y}\) respectively. One can use bilateral filter (BF)<d-cite key="tomasi1998bilateral"></d-cite> for more robust results, which considers both the pixelâs position \({p=[p_x, p_y]}\) and color intensities \((R_i,G_i,B_i)\). <br>
We set \({\delta_{f_i}=\delta_s}\) for the Gaussian filter and  \({\delta_{f_i}=(\delta_s,\delta_r)}\) for the bilateral filter. For simplicity, we set \({K =K^o=K^c}\) in our experiments due to the unavailable of the image \(o\) in advance.</p>

<p>For the LLE weights, it may be unstable to take a direct solver<d-cite key="roweis2000nonlinear"></d-cite>, when the number of neighbors of each point is larger than the space dimension. As described in<d-cite key="saul2003think"></d-cite>, a remedy \({W}\) can be computed by solving the point-wise regularized problem,</p>

\[\begin{equation}
	\label{eq:eq13}
	\begin{aligned}
		\min{\sum_i ({s_i}-{\sum_{j \in \Omega_i}{\omega_{i,j}^{s} {s_j}}})^2}+\epsilon {\Vert \omega^s\Vert}_2^2, \text{s.t.} \sum_{j \in \Omega_{i}} {\omega_{i,j}^{s}}=1.
	\end{aligned}
\end{equation}\]

<p>We refer the reader to some more complex regularizers such as the modified LLE algorithm<d-cite key="zhang2007mlle"></d-cite>, in which more robust solutions are given to distribute the contribution of neighbours to each point more uniformly.</p>

<p>After obtaining the \({K}\) and \({W}\), Eq. (\ref{eq:eq12}) can be solved by setting \({dE/do=0}\), giving the following linear system:
\(\begin{equation}
	\label{eq:eq14}
	\begin{aligned}
		(\alpha K^{T} K + \beta M^{T} M +\gamma I) o=\alpha K^T K c + \gamma s,
	\end{aligned}
\end{equation}\)</p>

<p>where \({L =\alpha K^T K + \beta M^T M +\gamma I}\) is a large-scale and sparse {Laplacian matrix}. Since \({L}\) is symmetric and semi-positive, Eq. (\ref{eq:eq14}) can be solved with the solvers such as Gauss-Seidel method and preconditioned conjugate gradients (PCG) method<d-cite key="saad2003iterative"></d-cite>.</p>

<p>In summary, our IIT algorithm includes: identifying the filter kernel for illumination fitting, computing LLE weights to encode image reflectance, and embedding the reflectance layer for image reconstruction. The whole minimization scheme is presented in <b>Algorithm 1</b>.</p>

<h2 id="experimental-results">Experimental Results</h2>

<p>We verify the proposed IIT model with the aid of an extra âexemplarâ image. As explained, our model may require a latent illumination layer in the sense that the underlying target illumination in many illumination-related tasks could deviate greatly from that of the original image. Nevertheless, it is not easy to provide such an illumination layer because of the inherent intractability of intrinsic image decomposition. Alternatively, we introduce a pre-computed âexemplarâ and use it to provide the underlying illumination approximately. Notice that, we specify the fine-balanced illumination distribution of the exemplar, but the proposed IIT framework does not rely on any specified exemplars.</p>

<p>We take two representative exemplars into account to verify the easy-fulfilled requirements of the exemplar and its benefits to image illumination manipulation.  The first class of exemplars is generated by the simple TMO methods â for example, contrast limited adaptive histogram equalization (CLAHE) method<d-cite key="zuiderveld1994contrast"></d-cite> which provides an exemplar with fine-balanced illumination distribution but distorted local details. The second class of exemplars is given by the existing cutting-edge methods, which usually provide an exemplar exhibiting better quality with not so strong local artifacts as the CLAHE ones. They are selected in consideration of the different properties in color, saturation, textures, noises, and illumination conditions.</p>

<h3>Verification and Robustness:</h3>

<p>Firstly, we show the results with a CLAHE exemplar. As shown in Figure 3,  the exemplar in Figure 3b is generated by the CLAHE algorithm with the fine-balanced illumination but distorted local details, while our IIT algorithm exhibits significant improvements in suppressing the local noises and distortions, especially around the swanâs âneckâ and âwingâ regions in Figure 3c and Figure 3d.  Moreover, tiny visual differences occur between using the Gaussian and bilateral filters.</p>

<div class="row mt-3"> 
    <div class="col-sm-3 mt-1 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_3a-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_3a-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_3a-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_3a.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

    </div>
    <div class="col-sm-3 mt-1 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_3b-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_3b-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_3b-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_3b.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Exemplar (CLAHE)</figcaption>

</figure>

    </div>
    <div class="col-sm-3 mt-1 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_3c-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_3c-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_3c-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_3c.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ GF (Ours)</figcaption>

</figure>

    </div>
    <div class="col-sm-3 mt-1 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_3d-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_3d-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_3d-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_3d.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ BF (Ours)</figcaption>

</figure>

    </div>
</div>
<div class="caption">
    Figure 3. Visual results of our IIT algorithm with the Gaussian and bilateral filters, respectively. (a) Source, (b) CLAHE exemplar<d-cite key="zuiderveld1994contrast"></d-cite>, (c) and (d) Our results. The noise and distortions are suppressed significantly in comparison to the CLAHE exemplar. TMQI (b)-(d): 0.845, 0.891, 0.898.
</div>

<p>We further explain the ability of our IIT method in fitting the latent image illumination determined by the exemplars. As shown in Figure 4, we present two typical exemplars given by the CLAHE algorithm<d-cite key="zuiderveld1994contrast"></d-cite>. The exemplars in Figure 4b and Figure 4d should have different underlying illumination, as they exhibit different levels of brightness regardless of the slight texture distortions. In this case, we set \(\alpha \!=\! 1.0\) and \(\gamma \!= \!0\) to enforce the output be close to the exemplar.  It is noticeable that the outputs in Figure 4c and Figure 4e reveal identical illumination distribution as that of the exemplars, and the non-consistent details in the exemplars are significantly suppressed in both cases. The results prove that a balanced image illumination instead of high-quality local details is the key ingredient to our IIT method. This observation is consistent with the assumption that the exemplar plays a determining role in improving the balance of image illumination, while local textures have little contribution to the output illumination.</p>

<div class="row">
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4a1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4a1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4a1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4a1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4a2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4a2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4a2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4a2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4b1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4b1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4b1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4b1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4b2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4b2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4b2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4b2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Exemplar 1</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4c1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4c1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4c1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4c1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4c2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4c2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4c2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4c2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ GF (Ours)</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4d1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4d1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4d1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4d1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4d2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4d2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4d2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4d2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Exemplar 2</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4e1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4e1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4e1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4e1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_4e2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_4e2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_4e2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_4e2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT + GF (Ours)</figcaption>

</figure>

    </div>
  </div>

<div class="caption">
    Figure 4. Visual comparison of our IIT algorithm by using exemplars with different levels of brightness. (a) Input image; (b) and (d) CLAHE exemplars<d-cite key="zuiderveld1994contrast"></d-cite>; (c) and (e) our IIT results.
</div>

<p>We additionally illustrate the robustness of our IIT method to the exemplar with strong local degraded details. As shown in Figure 5, we interpret the illumination compensation results on Yale Face dataset<d-cite key="schroff2011pose"></d-cite>. In this case, two typical exemplars (b) and (d) are introduced to show the robustness of our method to noise (Top) and textural distortions (Bottom). In the top row, the exemplars are cropped with different levels of Gaussian noise; while, in the bottom row, the exemplars suffer from serious textural distortions given by the CLAHE  algorithm\footnote{As interpreted in CLAHE<d-cite key="zuiderveld1994contrast"></d-cite>, we set the âNumTiles = \({16\times16}\)â and âNumTiles = \({32\times32}\)â for the exemplars in Figure 5b and Figure 5d, respectively. A larger âNumTilesâ leads to stronger textural distortions.}.  Again, our IIT method produces the satisfying results Figure 5c andFigure 5e that have identical illumination distribution as the exemplars, but the non-consistent textures are significantly suppressed, especially in âfaceâ regions. Moreover, the quality of outputs only drops slightly if we only increase the level of textural distortions but keep the illumination distribution invariant.</p>

<div class="row">
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5a1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5a1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5a1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5a1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5a2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5a2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5a2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5a2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5b1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5b1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5b1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5b1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5b2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5b2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5b2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5b2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Exemplar 1</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5c1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5c1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5c1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5c1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5c2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5c2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5c2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5c2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ GF (Ours)</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5d1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5d1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5d1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5d1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5d2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5d2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5d2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5d2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Exemplar 2</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5e1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5e1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5e1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5e1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_5e2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_5e2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_5e2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_5e2.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT + GF (Ours)</figcaption>

</figure>

    </div>
  </div>

<div class="caption">
    Figure 5. Illumination compensation on Yale Face dataset<d-cite key="schroff2011pose"></d-cite>. (a) Source, (b) and (d) CLAHE exemplars<d-cite key="zuiderveld1994contrast"></d-cite>, (c) and (e) results (IIT+ BF). TMQI, top: 0.935, 0.985, 0.833, 0.981; bottom: 0.922, 0.967, 0.897, 0.965.
</div>

<p>The above experimental results imply that image illumination can be faithfully controlled with the aid of an âexemplarâ,  because there is no need to pay much attention to local distortions and artifacts. As a result, it is easy to obtain a suitable exemplar by using many existing methods.  This advantage is mainly beneficial from the use of the smoothing operator in illumination loss and the translation-invariant property of the LLE âencodingâ model. On the one hand, the local details are mostly filtered out by the smoothing filter in the illumination loss, which remarkably weakens the impact of textural distortions; on the other hand, the inaccuracy of the smoothed illumination would be further corrected by the LLE âencodingâ model. The two aspects help to penalize the non-consistent structures existing in the exemplar significantly, thereby giving a practical way to reconstruct natural-looking results with high-quality consistent local details.</p>

<div class="row">
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6a-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6a-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6a-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6a.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6a1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6a1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6a1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6a1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6b-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6b-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6b-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6b.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6b1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6b1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6b1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6b1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Photoshop CC</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6c-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6c-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6c-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6c.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6c1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6c1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6c1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6c1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">NNASA Retinex</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6d-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6d-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6d-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6d.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_6d1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_6d1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_6d1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_6d1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ GF (Ours)</figcaption>

</figure>

    </div>
  </div>

<div class="caption">
    Figure 6. Visual comparison of image enhancement. The exemplars in (c) are produced by the state-of-art NASA Retinex<d-cite key="nasa_retinex"></d-cite>. TMQI,  top (b)-(d): 919, 0.943, 0.946; and bottom (b)-(d): 0.922, 0.916, 0.944.
</div>

<p>Secondly, we validate our IIT algorithm with an exemplar given by the state-of-the-art. In general, they produce an exemplar with much better quality than that of the CLAHE method. We adopt the default configurations or preferable parameter-settings as suggested in these methods. We set \({\alpha, \beta}\) and \({\gamma}\) to 0.95, \([10, 100]\) and 0.05, respectively, and the parameter \(\beta\) may vary according to the level of artifacts existing in exemplars. We let \({\alpha \gg \gamma}\) in view of the balanced illumination distribution of the exemplars. As shown in Figure 6, we compare the results with the Photoshop CC<d-cite key="photoshop_cc"></d-cite> and NASA Retinex<d-cite key="nasa_retinex"></d-cite> methods, where the exemplars are provided by the cutting-edge NASA Retinex<d-cite key="nasa_retinex"></d-cite>.  It is notable that Photoshop CC<d-cite key="photoshop_cc"></d-cite> gives the results with limited improvement in dark regions based on the built-in âHDR tone mappingâ tool, while the NASA Retinex method produces high-quality results with vivid color and contrast but also suffers from strong noise. In contrast, our IIT method attains similar enhanced results as the NASA Retinex with more consistent local textures compared with Photoshop CC<d-cite key="photoshop_cc"></d-cite> and NASA Retinex<d-cite key="nasa_retinex"></d-cite> results.</p>

<div class="row">
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7a-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7a-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7a-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7a.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7e-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7e-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7e-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7e.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Google Nik</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7b-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7b-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7b-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7b.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">CLAHE</figcaption>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7f-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7f-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7f-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7f.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">WESPE</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7c-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7c-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7c-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7c.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Photoshop CC</figcaption>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7g-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7g-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7g-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7g.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+GF (Ours)</figcaption>

</figure>

    </div>
    <div class="col">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7d-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7d-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7d-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7d.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">APE</figcaption>

</figure>

        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_7h-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_7h-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_7h-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_7h.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+BF (Ours)</figcaption>

</figure>

    </div>
  </div>

<div class="caption">
    Figure 7. Visual comparison on Cityscapes dataset<d-cite key="Cordts2016Cityscapes"></d-cite>.
		The exemplars used  in (g) and (h) are given by the state-of-art (f) WESPE<d-cite key="ignatov2017wespe"></d-cite>. TMQI, (b)-(h): 0.891, 0.913, 0.973, 0.893, 0.801, 0.921, 0.942.
</div>

<p>The result is further demonstrated on the Cityscapes dataset<d-cite key="Cordts2016Cityscapes"></d-cite>, in which the images suffer from visible degradation in color, saturation, and textures due to the low resolution and inappropriate illumination conditions. In this situation, it is often difficult for many existing methods to recover high-quality results. As shown in Figure 7, the prevailing commercial software, including Google Nik (GN)<d-cite key="google_nik"></d-cite>, Apple Photo Enhancer (APE) and Adobe Photoshop CC 2018<d-cite key="photoshop_cc"></d-cite> also reveal drawbacks in producing natural-looking results, where the automatic parameter-settings are adopted for comparison. Recent deep-learning approaches such as WESPE<d-cite key="ignatov2017wespe"></d-cite> provide a solution to visual-pleasant results, but there still exists some unpleasant artifacts such as over-exaggerated details around the salient edges. In contrast, our IIT method can be applied to correct these artifacts for high-quality consistent local details. As we can see in Figure 7g and Figure 7h, we take the WESPE result as the exemplar and the local structures of âstreet lampâ are precisely preserved and the âroadâ reveals little texture distortions compared with the other methods.</p>

<p>We now have investigated the role of exemplars in our IIT method and demonstrated the robustness to produce high-quality results under different types of exemplars. We also conclude that many existing methods can be used to provide such an exemplar. As interpreted before, the whole procedure, with the aid of an exemplar, is eventually formulated into a generalized optimization framework, giving a closed-form solution to a wide range of illumination-related tasks. The favorable results definitively benefit from both the smoothing operators in illumination loss â which helps to reduce the impact of local details in the exemplar, and the LLE encode in reflectance loss â which adaptively extracts local details from the original image and then embeds them onto a new smoothing surface given by the exemplar. The merit is the use of an exemplar, which significantly simplifies image illumination manipulation because of avoiding an explicit intrinsic image decomposition.</p>

<h3>Quantitative Evaluation:</h3>

<p>In this section, we further take a quantitative evaluation based on the following datasets:  Cityscapes<d-cite key="Cordts2016Cityscapes"></d-cite>, NASA Retinex<d-cite key="nasa_retinex"></d-cite> and DPED<d-cite key="ignatov2017dslr"></d-cite>. The Cityscapes<d-cite key="Cordts2016Cityscapes"></d-cite> dataset has 20 low-resolution images with slightly unbalanced illumination distribution, which are challenging for many existing methods; while NASA Retinex<d-cite key="nasa_retinex"></d-cite> and DPED<d-cite key="ignatov2017dslr"></d-cite> datasets have 26 and 16 images respectively, which have higher resolution but also reveals strong imbalance illumination distribution. The proposed IIT method is compared with the cutting-edge methods, including NASA Retinex<d-cite key="nasa_retinex"></d-cite>, Google Nik (GN)<d-cite key="google_nik"></d-cite>, Apple Photo Enhancer (APE),  Adobe Photoshop CC 2018<d-cite key="photoshop_cc"></d-cite>, WESPE method<d-cite key="ignatov2017wespe"></d-cite>, and the exemplars in the datasets are provided by the Retinex<d-cite key="nasa_retinex"></d-cite>, WESPE and CLAHE methods, respectively.</p>

<p>In general, image quality assessment can be categorized into full-reference and no-reference approaches. The full-reference methods always require the corresponding ground-truth images for high-accuracy assessment, which, however, are always not available in the case of illumination-related tasks. As a result, it is difficult to take an objective full-reference evaluation. In contrast, no-reference methods require no ground-truth images but rely on statistical models to measure the degradation of an image. Recent no-reference approaches, in particular these deep-learning ones, have also shown promising success in predicting the quality of images. Specifically, we employ a quantitative evaluation based on the Tone Mapped Image Quality Index (TMQI)<d-cite key="yeganeh2013objective"></d-cite>, Integrated Local Natural Image Quality Evaluator (IL-NIQE)<d-cite key="zhang2015feature"></d-cite> and Neural Image Assessment (NIMA)<d-cite key="talebi2018nima"></d-cite>. The TMQI<d-cite key="yeganeh2013objective"></d-cite> index is a full-reference image assessment method built on the source and output images, which is originally proposed to provide an objective image quality assessment for HDR image compression. In TMQI index, Structural Fidelity (SF) and Statistical Naturalness (SN) are considered to provide an objective quality assessment. The SF index is based on the multi-scale structural similarity (SSIM) approach<d-cite key="wang2004image"></d-cite> to extract structural information from the visual scene and provides a perceptual predictor of structural fidelity. The SN index provides a statistic metric for the output image, which takes the natural image statistics of brightness, contrast, visibility and details into account. IL-NIQE<d-cite key="zhang2015feature"></d-cite> and  NIMA<d-cite key="talebi2018nima"></d-cite> are two no-reference image assessments. The former is a learning method based on natural image statistics features derived from color, luminance,  gradient and structure information; and the latter attempts to predict consistent aesthetic scores with human opinions using convolutional neural networks. The NIMA<d-cite key="talebi2018nima"></d-cite> method is trained on a large-scale natural image dataset for perceptually-aware no-reference quality assessment. The statistical results are shown in \textbf{Table} \ref{tab:tab1}, where the best two results are highlighted with \textbf{bold} and \textbf{underline}, respectively. The advantage of our IIT method is noticeable with 19 top-two places in total 30 indices compared with the state-of-art on real-world image datasets.</p>

<h2 id="more-extensions">More Extensions</h2>

<p>It is easy to see the proposed IIT method can be extended to high dynamic range (HDR) image compression to improve the visibility of dark regions. Similarly, it helps to suppress the distorted details or artifacts, providing the comparable or superior results than the prevailing cutting-edge methods. In this case, we apply the proposed IIT model on image luminance with the same aforementioned configurations. The saturation is restored with a heuristic de-saturation setup as described in<d-cite key="fattal2002gradient"></d-cite>.</p>

\[\begin{equation}
	\begin{aligned}
		C_{out}={\left(\frac{C_{in}} {L_{in}}\right)}^s L_{out},
	\end{aligned}
	\label{f2}
\end{equation}\]

<p>where \(C =\{ R,G,B\}\) are red, green and blue channels of color images, \(L_{in}\) and \(L_{out}\) denote the source and mapped luminance, and \(s\) controls the saturation with an empirical value between 0.4 and 0.6 to produce satisfying results.</p>

<p>We show two examples of HDR image compression with visual comparisons in Figure 8, where the exemplars are generated by the CLAHE algorithm<d-cite key="zuiderveld1994contrast"></d-cite>. We set the parameter \(s = 0.5\) and \(s=0.6\) for the two cases, respectively. As we can see, the proposed IIT method is capable of producing high-quality results as that of the gradient-domain (GD) compression<d-cite key="fattal2002gradient"></d-cite> and weighted least square (WLS) filtering method<d-cite key="farbman2008edge"></d-cite>.</p>

<div class="row justify-content-md-center"> 
  <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8a-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8a-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8a-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8a.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Ward's</figcaption>

</figure>

      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8d-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8d-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8d-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8d.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Ward's</figcaption>

</figure>

  </div>
    <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8b-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8b-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8b-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8b.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">GD</figcaption>

</figure>

      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8e-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8e-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8e-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8e.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">WLS</figcaption>

</figure>

  </div>
    <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8c-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8c-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8c-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8c.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+BF (Ours)</figcaption>

</figure>

      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_8f-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_8f-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_8f-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_8f.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+BF (Ours)</figcaption>

</figure>

  </div>
</div>
<div class="caption">
    Figure 8. Visual comparison of  the HDR image compression using the CLAHE exemplars<d-cite key="zuiderveld1994contrast"></d-cite>. TMQI, top (a)-(c): 0.923, 0.948, 0.944; bottom (d)-(f): 0.912, 0.940, 0.953.
</div>

<p>We additionally illustrate that the structure-consistent property of the proposed IIT method makes it applicable to much more complex situations beyond the above illumination-related tasks. Specifically, it is possible to be used as a building block for color transform<d-cite key="reinhard2001color"></d-cite> and style transfer<d-cite key="gatys2016image, jing2019neural, li2017universal"></d-cite>, where a high-level vision image-to-image translation is always deduced to produce stylized results for artistic purpose. In the literature, many approaches, especially the deep-learning ones<d-cite key="jing2019neural, li2017universal"></d-cite>, have been explored to obtain artistic-like stylized results. Despite their great success, they occasionally produce unexpected distortions or unrealistic artifacts that not occur in real photographs. We illustrate that the proposed IIT model is possible to suppress these non-consistent textures, enjoying a photo-realistic style transfer as proposed in the recent work<d-cite key="lu2019closed, yoo2019photorealistic"></d-cite>. The understanding for style transfer, somewhat, remains elusive<d-cite key="jing2019neural"></d-cite> and the discussion for more details is out of scope here, we conjecture here that the image-to-image translation procedure can be also interpreted under the intrinsic images of Eq. (\ref{eq:eq1}).  The difference from the illumination-related works is that both illumination and reflectance layers in style transfer vary significantly, leading to a strong discrepancy in image color, saturation, texture, style, and so on.</p>

<p>We briefly illustrate the procedure by giving an input image and a reference style, where a stylized exemplar is firstly generated by the existing style transfer methods such as the deep learning ones<d-cite key="gatys2016image,  jing2019neural, li2017universal, huang2017arbitrary"></d-cite>.  Our IIT algorithm is then used to refine the local distortions of the stylized exemplar. As shown in Figure 9, an image Figure 9a is first transformed into the stylized exemplar Figure 9c using two deep learning-based methods<d-cite key="gatys2016image, jing2019neural"></d-cite> under the guidance of reference style Figure 9d; and a photo-realistic result Figure 9b is obtained under the IIT model with the stylized image as the corresponding exemplar. As we can see,  our IIT algorithm produces satisfying results  that have identical saturation as the exemplar and high-quality consistent structures as the input image.  The local textures in the âskyâ region are remarkably removed, leading to the photo-realistic stylized results. The startling results demonstrate the powerful ability of the proposed IIT method in suppressing the local distortions, and it further turns out the robustness of our method to the exemplar image.</p>

<div class="row justify-content-md-center"> 
  <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9a-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9a-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9a-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9a.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
    <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9b-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9b-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9b-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9b.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
  <div class="col col-lg-3">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9c-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9c-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9c-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9c.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
  <div class="col col-lg-2">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9d-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9d-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9d-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9d.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
  <div class="col col-lg-3">
     <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9a1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9a1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9a1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9a1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Input</figcaption>

</figure>

  </div>
    <div class="col col-lg-3">
     <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9b1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9b1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9b1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9b1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">IIT+ BF (Ours)</figcaption>

</figure>

  </div>
  <div class="col col-lg-3">
     <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9c1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9c1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9c1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9c1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture><figcaption class="subcaption">Stylizied Exemplar</figcaption>

</figure>

  </div>
  <div class="col col-lg-2">
      <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/iit/Fig_9d1-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/iit/Fig_9d1-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/iit/Fig_9d1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/iit/Fig_9d1.png" class="img-fluid" width="auto" height="auto" alt="zoom" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

  </div>
</div>
<div class="caption">
    Figure 9. Photorealistic style transfer. Given an image (a) and a reference style (d), a stylized exemplar (c) may be provided by these deep-learning methods<d-cite key="gatys2016image, jing2019neural, li2017universal, huang2017arbitrary"></d-cite>, which is further refined by our IIT model as shown in (b) with more consistent textures and structures.
</div>

<h2 id="conclusion">Conclusion</h2>

<p>This paper has described an intrinsic image transfer algorithm,  which is rather different from recent trends towards making an intrinsic image decomposition.  This model creates a local image translation between two image surfaces and produces high-quality results in a wide range of illumination manipulation tasks.  One drawback is that the algorithm is time-consuming for the need of computing the large-scale LLE weights and PCG solver. It is possible to be addressed with a sub-sampling strategy for efficiency, which is left for future work.</p>

        </div>
          
        
      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/paper_reference.bib"></d-bibliography><div id="giscus_thread" style="max-width: 960px; margin: 0 auto;">
  <script>
    let giscusTheme = localStorage.getItem("theme");
    let giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo": "Junqing-Huang/al-folio",
        "data-repo-id": "MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==",
        "data-category": "Comments",
        "data-category-id": "DIC_kwDOA5PmLc4CTBt6",
        "data-mapping": "title",
        "data-strict": "1",
        "data-reactions-enabled": "1",
        "data-emit-metadata": "0",
        "data-input-position": "bottom",
        "data-theme": giscusTheme,
        "data-lang": "en",
        "crossorigin": "anonymous",
        "async": "",
    };


    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("giscus_thread").appendChild(giscusScript);
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
</noscript>
</div>
<!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2023 Junqing  Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

      <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

      
      

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    </div>
  
</body>
</html>
